{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sub(sub, index_of_ad, index_of_score, expected_length):\n",
    "    seen = []\n",
    "    uniqs = []\n",
    "    # explicitly check ordering\n",
    "    i = 100\n",
    "    sub.sort(key=operator.itemgetter(index_of_score), reverse=True)\n",
    "    for entry in sub:\n",
    "        if entry[index_of_score] > i:\n",
    "            print \"ORDERING PROBLEM\"\n",
    "            return None\n",
    "        i = entry[index_of_score]\n",
    "        #else:\n",
    "        #    print type(entry)\n",
    "    # de-dupe\n",
    "    for entry in sub:\n",
    "        if entry[index_of_ad] not in seen:\n",
    "            uniqs.append(entry)\n",
    "            seen.append(entry[index_of_ad])\n",
    "    # explicitly sort by score after de-duping\n",
    "    uniqs.sort(key=operator.itemgetter(index_of_score), reverse=True)\n",
    "    # explicitly check ordering\n",
    "    i = 100\n",
    "    for entry in uniqs:\n",
    "        if entry[index_of_score] > i:\n",
    "            print \"ORDERING PROBLEM\"\n",
    "            return None\n",
    "        i = entry[index_of_score]\n",
    "    return uniqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool_depth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_file =  '../data/post_hoc_annotations/post_hoc_point_fact_combined.json'\n",
    "    \n",
    "with open(gt_file, 'r') as f:\n",
    "    gt = eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_path = '../data/team_submissions/'\n",
    "submission_paths_dict = {}\n",
    "submission_paths_dict['Georgetown'] = {}\n",
    "submission_paths_dict['Georgetown']['NYU'] = submission_path + 'Georgetown/DomainDiscovery/NYU_pointfact.json'\n",
    "submission_paths_dict['Georgetown']['JPL'] = submission_path + ('Georgetown/DomainDiscovery/'\n",
    "                                                           'Georgetown_Submission_2_8/JPL/JPL_Point_Fact_2_9.json')\n",
    "submission_paths_dict['Georgetown']['HG'] = submission_path + ('Georgetown/DomainDiscovery/'\n",
    "                                                          'Georgetown_Submission_2_8/HG/HG_Point_Fact_2_9.json')\n",
    "\n",
    "submission_paths_dict['Uncharted'] = {}\n",
    "submission_paths_dict['Uncharted']['NYU'] = submission_path + ('Uncharted/DomainDiscovery/uncharted_NYU_DD.json')\n",
    "submission_paths_dict['Uncharted']['JPL'] = submission_path + ('Uncharted/DomainDiscovery/uncharted_JPL_DD.json')\n",
    "submission_paths_dict['Uncharted']['HG'] = submission_path + ('Uncharted/DomainDiscovery/uncharted_HG_DD.json')\n",
    "\n",
    "\n",
    "submission_paths_dict['ISI'] = {}\n",
    "submission_paths_dict['ISI']['NYU'] = submission_path + ('ISI/DomainDiscovery/'\n",
    "                               'isi-nyu-answers-dig-extractions/'\n",
    "                               'properly_formatted_submissions/'\n",
    "                               'formatted_post_point_fact'\n",
    "                               '_parsed_fixed_all_answers.json')\n",
    "submission_paths_dict['ISI']['JPL'] = submission_path + ('ISI/DomainDiscovery/'\n",
    "                               'jpl_answers_isi/'\n",
    "                               'properly_formatted_submissions/'\n",
    "                               'formatted_PF'\n",
    "                               '-queries-parsed_all_answers.json')\n",
    "submission_paths_dict['ISI']['HG'] = submission_path + ('ISI/DomainDiscovery/'\n",
    "                               'hg_all_asnwers/'\n",
    "                               'properly_formatted_submissions/'\n",
    "                               'formatted_post_point_fact'\n",
    "                               '_parsed_fixed_all_answers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submitted_answers = {}\n",
    "submitted_answers['NYU'] = {}\n",
    "submitted_answers['JPL'] = {}\n",
    "submitted_answers['HG'] = {}\n",
    "\n",
    "for dataset in submitted_answers.keys():\n",
    "    for qid in gt.keys():\n",
    "        submitted_answers[dataset][qid] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Georgetown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "NO SUBMISSION FOR QUESTION1647\n",
      "NO SUBMISSION FOR QUESTION363\n",
      "POOL DEPTH REACHED\n",
      "NO SUBMISSION FOR QUESTION1647\n",
      "NO SUBMISSION FOR QUESTION363\n",
      "POOL DEPTH REACHED\n",
      " \n",
      "HG\n",
      "526\n",
      "JPL\n",
      "647\n",
      "NYU\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "id_pos = 1\n",
    "score_pos = 2\n",
    "ans_length = 3 \n",
    "id_length = 64\n",
    "clus_type = 'Point Fact'\n",
    "\n",
    "for dataset in submitted_answers.keys():\n",
    "    file_path = submission_paths_dict['Georgetown'][dataset]\n",
    "    f = open(file_path, 'r')\n",
    "    data = eval(f.read())\n",
    "\n",
    "    for qid in gt.keys():\n",
    "        submissions = []\n",
    "        for entry in data:\n",
    "            # We are only evaluating some of them\n",
    "            if entry['id'] == qid:\n",
    "                submissions = clean_sub(entry['answer'], id_pos, score_pos, ans_length)\n",
    "        if len(submissions) == 0:\n",
    "            print 'NO SUBMISSION FOR QUESTION{0}'.format(qid)\n",
    "        # Reconfirming no dupes\n",
    "        if len(submissions) != len(list(set(tuple(i) for i in submissions))):\n",
    "            print \"PROBLEM WITH DUPLICATED DOC IDS\"\n",
    "            break\n",
    "        # Now that submissions are sorted, only take top N\n",
    "        if len(submissions) > pool_depth:\n",
    "            submissions = submissions[:pool_depth]\n",
    "            print \"POOL DEPTH REACHED\"\n",
    "        submitted_ads = [entry[id_pos] for entry in submissions]\n",
    "        submitted_answers[dataset][qid].extend(submitted_ads)\n",
    "\n",
    "print ' '\n",
    "for dataset in submitted_answers.keys():\n",
    "    print dataset\n",
    "    total = 0\n",
    "    for qid in submitted_answers[dataset].keys():\n",
    "        total += len(submitted_answers[dataset][qid])\n",
    "    print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "HG\n",
      "1959\n",
      "JPL\n",
      "2147\n",
      "NYU\n",
      "740\n"
     ]
    }
   ],
   "source": [
    "id_pos = 1\n",
    "score_pos = 2\n",
    "ans_length = 3 \n",
    "id_length = 64\n",
    "clus_type = 'Point Fact'\n",
    "\n",
    "for dataset in submitted_answers.keys():\n",
    "    file_path = submission_paths_dict['ISI'][dataset]\n",
    "    f = open(file_path, 'r')\n",
    "    data = eval(f.read())\n",
    "\n",
    "    for qid in gt.keys():\n",
    "        submissions = []\n",
    "        for entry in data:\n",
    "            # We are only evaluating some of them\n",
    "            if entry['question_id'].split('-')[0] == qid:\n",
    "                submissions = clean_sub(entry['answer'], id_pos, score_pos, ans_length)\n",
    "        # Reconfirming no dupes\n",
    "        if len(submissions) != len(list(set(tuple(i) for i in submissions))):\n",
    "            print \"PROBLEM WITH DUPLICATED DOC IDS\"\n",
    "            break\n",
    "        # Now that submissions are sorted, only take top N\n",
    "        if len(submissions) > pool_depth:\n",
    "            submissions = submissions[:pool_depth]\n",
    "            print \"POOL DEPTH REACHED\"\n",
    "        submitted_ads = [entry[id_pos] for entry in submissions]\n",
    "        submitted_answers[dataset][qid].extend(submitted_ads)\n",
    "\n",
    "print ' '\n",
    "for dataset in submitted_answers.keys():\n",
    "    print dataset\n",
    "    total = 0\n",
    "    for qid in submitted_answers[dataset].keys():\n",
    "        total += len(submitted_answers[dataset][qid])\n",
    "    print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncharted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      "POOL DEPTH REACHED\n",
      " \n",
      "HG\n",
      "3239\n",
      "JPL\n",
      "3468\n",
      "NYU\n",
      "1934\n"
     ]
    }
   ],
   "source": [
    "id_pos = 1\n",
    "score_pos = 2\n",
    "ans_length = 3 \n",
    "id_length = 64\n",
    "clus_type = 'Point Fact'\n",
    "\n",
    "for dataset in submitted_answers.keys():\n",
    "    file_path = submission_paths_dict['Uncharted'][dataset]\n",
    "    f = open(file_path, 'r')\n",
    "    all_data = eval(f.read())\n",
    "    data = []\n",
    "    for entry in all_data:\n",
    "        if entry['questionType'] == clus_type:\n",
    "            data.append(entry)\n",
    "\n",
    "    for qid in gt.keys():\n",
    "        submissions = []\n",
    "        for entry in data:\n",
    "            # We are only evaluating some of them\n",
    "            if entry['question_id'] == qid:\n",
    "                submissions = clean_sub(entry['answers'], id_pos, score_pos, ans_length)\n",
    "        # Reconfirming no dupes\n",
    "        if len(submissions) != len(list(set(tuple(i) for i in submissions))):\n",
    "            print \"PROBLEM WITH DUPLICATED DOC IDS\"\n",
    "            break\n",
    "        # Now that submissions are sorted, only take top N\n",
    "        if len(submissions) > pool_depth:\n",
    "            submissions = submissions[:pool_depth]\n",
    "            print \"POOL DEPTH REACHED\"\n",
    "        submitted_ads = [entry[id_pos] for entry in submissions]\n",
    "        submitted_answers[dataset][qid].extend(submitted_ads)\n",
    "        \n",
    "print ' '\n",
    "for dataset in submitted_answers.keys():\n",
    "    print dataset\n",
    "    total = 0\n",
    "    for qid in submitted_answers[dataset].keys():\n",
    "        total += len(submitted_answers[dataset][qid])\n",
    "    print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniq_subs = {}\n",
    "for dataset in submitted_answers.keys():\n",
    "    uniq_subs[dataset] = {}\n",
    "    # Here we'll take the \"unique submissions PER QUESTION\"\n",
    "    # Therefore, if the same document is considerred twice, \n",
    "    # once each for two different questions\n",
    "    # that is considered as two \"unique submissions\"\n",
    "    # since each time, the document has a new chance of being found relevant\n",
    "    for qid in submitted_answers[dataset].keys():\n",
    "        temp = submitted_answers[dataset][qid]\n",
    "        temp = list(set(temp))\n",
    "        uniq_subs[dataset][qid] = len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "NYU\n",
      "1825\n",
      " \n",
      "HG\n",
      "3102\n",
      " \n",
      "JPL\n",
      "3442\n"
     ]
    }
   ],
   "source": [
    "for dataset in uniq_subs.keys():\n",
    "    print ' '\n",
    "    print dataset\n",
    "    total = 0\n",
    "    for qid in uniq_subs[dataset].keys():\n",
    "        total += uniq_subs[dataset][qid]\n",
    "    print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submitted_answers['NYU']['799'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
