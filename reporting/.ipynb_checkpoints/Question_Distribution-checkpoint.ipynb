{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_query(qtype, qlines):\n",
    "    if qtype == 'Point Fact':\n",
    "        qfeat = qlines[1].split('?')[2]\n",
    "    if qtype in ['Cluster Aggregate', 'Pure Aggregate GT', 'Pure Aggregate DD']:\n",
    "        qfeat = qlines[1].split('?')[1]\n",
    "    return qfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_filter(qtype, qlines):\n",
    "    filt_list = []\n",
    "    # Determine type of seed feature\n",
    "    if qtype not in ['Point Fact', 'Pure Aggregate GT', 'Pure Aggregate DD']:\n",
    "        if '@' in qlines[4]:\n",
    "            filt_list = ['email']\n",
    "        else:\n",
    "            filt_list = ['phone']\n",
    "    # Determine extra filters\n",
    "    if qtype != 'Cluster Identification':\n",
    "        for line in qlines:\n",
    "            chunkers = line.split(' ')\n",
    "            for chunk in chunkers:\n",
    "                if 'qpr:' in chunk:\n",
    "                    newchunk = chunk.replace('qpr:', '*')\n",
    "                    filt_feat = newchunk.split('*')[1]\n",
    "                    if filt_feat.lower() not in ['ad', 'ad;', '', 'cluster', '<http://istresearch.com/qpr>', 'seed']:\n",
    "                        # Make sure this isn't the query term:\n",
    "                        # Remeber it's not a query term per se for Cluster Facet\n",
    "                        if qtype != 'Cluster Facet':\n",
    "                            if filt_feat not in qlines[1]:\n",
    "                                filt_list.append(filt_feat)\n",
    "                        else:\n",
    "                            filt_list.append(filt_feat)\n",
    "                        \n",
    "    filt_set = list(set(filt_list))\n",
    "    \n",
    "    return filt_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_type = {}\n",
    "#question_type['Point Fact'] = '../questions/post_point_fact_V3.json'\n",
    "#question_type['Cluster Identification'] = '../questions/post_cluster_identification.json'\n",
    "#question_type['Cluster Facet'] = '../questions/post_cluster_facet.json'\n",
    "#question_type['Cluster Aggregate'] = '../questions/post_aggregate_V2.json'\n",
    "\n",
    "#question_type['Pure Aggregate GT'] = '../questions/pure_agg_gt_questions_V3.json'\n",
    "question_type['Pure Aggregate DD'] = '../questions/pure_agg_dd_questions_V3.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for reporting in the distribution of questions chosen for evaluation\n",
    "# First filename\n",
    "#chosen_questions_file = '../data/annotation_prep/dd_clustering/chosen_questions.json'\n",
    "# Second file name after 2 rounds. This one is ok to use:\n",
    "chosen_questions_file = '../data/annotation_prep/dd_clustering/FIRST_ROUND_chosen_questions.json'\n",
    "with open(chosen_questions_file, 'r') as f:\n",
    "    chosen_questions = eval(f.read())\n",
    "    \n",
    "selected_questions = {}\n",
    "for qtype in question_type.keys():\n",
    "    if qtype in ['Cluster Identification', 'Cluster Facet', 'Cluster Aggregate']:\n",
    "        selected_questions[qtype] = chosen_questions['NYU'][qtype].keys()\n",
    "\n",
    "selected_questions['Point Fact'] = [\n",
    "    '1647',\n",
    "    '392',\n",
    "    '1707',\n",
    "    '217',\n",
    "    '510',\n",
    "    '799',\n",
    "    '363',\n",
    "    '1597',\n",
    "    '1180',\n",
    "    '1159',\n",
    "    '1035',\n",
    "    '1038',\n",
    "    '2304',\n",
    "    '1339',\n",
    "    '284'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Default Question Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PURE AGGREGATE DD\n",
      " \n",
      "Make filter table 6 rows (plus 1 for heading)\n",
      " \n",
      "age 4\n",
      "name 3\n",
      "price 2\n",
      "phone 2\n",
      "location 2\n",
      "email 2\n",
      " \n",
      "Make query table 8 rows (plus 1 for heading)\n",
      " \n",
      "age  6\n",
      "email  2\n",
      "location  2\n",
      "hair_color  1\n",
      "price  1\n",
      "weight  1\n",
      "phone  1\n",
      "height  1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for qtype in question_type.keys():\n",
    "    filter_features = {}\n",
    "    query_features = {}\n",
    "    agg_function = {}\n",
    "    # Obtain questions\n",
    "    file_path = question_type[qtype]\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Find features of question\n",
    "    for question in data:\n",
    "        qlines = question['SPARQL'][-1].split('\\n')\n",
    "        # Find what feature is queried\n",
    "        if qtype not in ['Cluster Identification', 'Cluster Facet']:\n",
    "            qfeat = extract_query(qtype, qlines)\n",
    "            if qfeat in query_features.keys():\n",
    "                query_features[qfeat] += 1\n",
    "            else:\n",
    "                query_features[qfeat] = 1\n",
    "        filt_set = extract_filter(qtype, qlines)\n",
    "        for filt in filt_set:\n",
    "            if filt in filter_features.keys():\n",
    "                filter_features[filt] += 1\n",
    "            else:\n",
    "                filter_features[filt] = 1\n",
    "    \n",
    "    # Format Output for Table\n",
    "    print qtype.upper()\n",
    "    print ' '\n",
    "    print 'Make filter table {} rows (plus 1 for heading)'.format(len(filter_features))\n",
    "    print ' '\n",
    "    sorted_filts = sorted(filter_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_filts:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '\n",
    "    print 'Make query table {} rows (plus 1 for heading)'.format(len(query_features))\n",
    "    print ' '\n",
    "    sorted_queries = sorted(query_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_queries:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Specially Selected Question Distribution (in case of special eval on DD for PF, CI, CF, and CA question types only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for qtype in question_type.keys():\n",
    "    filter_features = {}\n",
    "    query_features = {}\n",
    "    agg_function = {}\n",
    "    # Obtain questions\n",
    "    file_path = question_type[qtype]\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Find features of question\n",
    "    for question in data:\n",
    "        if question['id'] in selected_questions[qtype]:\n",
    "            qlines = question['SPARQL'][-1].split('\\n')\n",
    "            # Find what feature is queried\n",
    "            if qtype not in ['Cluster Identification', 'Cluster Facet']:\n",
    "                qfeat = extract_query(qtype, qlines)\n",
    "                if qfeat in query_features.keys():\n",
    "                    query_features[qfeat] += 1\n",
    "                else:\n",
    "                    query_features[qfeat] = 1\n",
    "            filt_set = extract_filter(qtype, qlines)\n",
    "            for filt in filt_set:\n",
    "                if filt in filter_features.keys():\n",
    "                    filter_features[filt] += 1\n",
    "                else:\n",
    "                    filter_features[filt] = 1\n",
    "    \n",
    "    # Format Output for Table\n",
    "    print qtype.upper()\n",
    "    print ' '\n",
    "    print 'Make filter table {} rows (plus 1 for heading)'.format(len(filter_features))\n",
    "    print ' '\n",
    "    sorted_filts = sorted(filter_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_filts:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '\n",
    "    print 'Make query table {} rows (plus 1 for heading)'.format(len(query_features))\n",
    "    print ' '\n",
    "    sorted_queries = sorted(query_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_queries:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'SPARQL': [u\"PREFIX qpr:<http://istresearch.com/qpr>\\nSELECT ?name ((count(?ad)) AS ?count)\\nWHERE\\n{\\t?ad a qpr:Ad ;\\n\\tqpr:phone '4388042437' ;\\n\\tqpr:name ?name .\\n}\\nGROUP BY ?name\\nORDER BY DESC(?count)\\nLIMIT 1\",\n",
       "  u\"PREFIX qpr:<http://istresearch.com/qpr>\\nSELECT ?name ?ad\\nWHERE\\n{\\t?ad a qpr:Ad ;\\n\\tqpr:phone '4388042437' ;\\n\\tqpr:name ?name .\\n}\"],\n",
       " u'id': 1,\n",
       " u'question': u'What is the most common name found in ads with the phone number 4388042437?',\n",
       " u'type': u'MODE'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "print data[0]['SPARQL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'height' in qlines[1]:\n",
    "    print \"hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'name '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlines[1].split('?')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qfeat = extract_query(qtype, qlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls ../data/annotation_prep/dd_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
