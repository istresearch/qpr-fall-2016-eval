{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_query(qtype, qlines):\n",
    "    if qtype == 'Point Fact':\n",
    "        qfeat = qlines[1].split('?')[2]\n",
    "    if qtype == 'Cluster Aggregate':\n",
    "        qfeat = qlines[1].split('?')[1]\n",
    "    return qfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_filter(qtype, qlines):\n",
    "    filt_list = []\n",
    "    # Determine type of seed feature\n",
    "    if qtype != 'Point Fact':\n",
    "        if '@' in qlines[4]:\n",
    "            filt_list = ['email']\n",
    "        else:\n",
    "            filt_list = ['phone']\n",
    "    # Determine extra filters\n",
    "    if qtype != 'Cluster Identification':\n",
    "        for line in qlines:\n",
    "            chunkers = line.split(' ')\n",
    "            for chunk in chunkers:\n",
    "                if 'qpr:' in chunk:\n",
    "                    newchunk = chunk.replace('qpr:', '*')\n",
    "                    filt_feat = newchunk.split('*')[1]\n",
    "                    if filt_feat.lower() not in ['ad', '', 'cluster', '<http://istresearch.com/qpr>', 'seed']:\n",
    "                        # Make sure this isn't the query term:\n",
    "                        # Remeber it's not a query term per se for Cluster Facet\n",
    "                        if qtype != 'Cluster Facet':\n",
    "                            if filt_feat not in qlines[1]:\n",
    "                                filt_list.append(filt_feat)\n",
    "                        else:\n",
    "                            filt_list.append(filt_feat)\n",
    "                        \n",
    "    filt_set = list(set(filt_list))\n",
    "    \n",
    "    return filt_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_type = {}\n",
    "question_type['Point Fact'] = '../questions/post_point_fact_V3.json'\n",
    "#question_type['Cluster Identification'] = '../questions/post_cluster_identification.json'\n",
    "#question_type['Cluster Facet'] = '../questions/post_cluster_facet.json'\n",
    "#question_type['Cluster Aggregate'] = '../questions/post_aggregate_V2.json'\n",
    "\n",
    "#question_type['Pure Aggregate GT'] = '../questions/pure_agg_gt_questions_V3.json'\n",
    "#question_type['Pure Aggregate DD'] = '../questions/post_aggregate_V2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for reporting in the distribution of questions chosen for evaluation\n",
    "chosen_questions_file = '../data/annotation_prep/dd_clustering/chosen_questions.json'\n",
    "with open(chosen_questions_file, 'r') as f:\n",
    "    chosen_questions = eval(f.read())\n",
    "    \n",
    "selected_questions = {}\n",
    "for qtype in question_type.keys():\n",
    "    if qtype in ['Cluster Identification', 'Cluster Facet', 'Cluster Aggregate']:\n",
    "        selected_questions[qtype] = chosen_questions['NYU'][qtype].keys()\n",
    "\n",
    "\n",
    "selected_questions['Point Fact'] = [\n",
    "    '1647',\n",
    "    '392',\n",
    "    '1707',\n",
    "    '217',\n",
    "    '510',\n",
    "    '799',\n",
    "    '363',\n",
    "    '1597',\n",
    "    '1180',\n",
    "    '1159',\n",
    "    '1035',\n",
    "    '1038',\n",
    "    '2304',\n",
    "    '1339',\n",
    "    '284'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Default Question Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT FACT\n",
      " \n",
      "Make filter table 17 rows (plus 1 for heading)\n",
      " \n",
      "phone 69\n",
      "name 45\n",
      "content 41\n",
      "age 30\n",
      "location 26\n",
      "email 24\n",
      "height 22\n",
      "title 21\n",
      "post_date 18\n",
      "hair_color 16\n",
      "weight 15\n",
      "price 12\n",
      "ethnicity 11\n",
      "review_site_id 5\n",
      "social_media_id 3\n",
      "services 3\n",
      "street_address 3\n",
      " \n",
      "Make query table 14 rows (plus 1 for heading)\n",
      " \n",
      "location 25\n",
      "age 14\n",
      "name 13\n",
      "phone 12\n",
      "ethnicity 11\n",
      "email 8\n",
      "review_site_id 6\n",
      "hair_color 3\n",
      "post_date 3\n",
      "price 2\n",
      "weight 1\n",
      "social_media_id 1\n",
      "services 1\n",
      "height 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for qtype in question_type.keys():\n",
    "    filter_features = {}\n",
    "    query_features = {}\n",
    "    agg_function = {}\n",
    "    # Obtain questions\n",
    "    file_path = question_type[qtype]\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Find features of question\n",
    "    for question in data:\n",
    "        qlines = question['SPARQL'][-1].split('\\n')\n",
    "        # Find what feature is queried\n",
    "        if qtype not in ['Cluster Identification', 'Cluster Facet']:\n",
    "            qfeat = extract_query(qtype, qlines)\n",
    "            if qfeat in query_features.keys():\n",
    "                query_features[qfeat] += 1\n",
    "            else:\n",
    "                query_features[qfeat] = 1\n",
    "        filt_set = extract_filter(qtype, qlines)\n",
    "        for filt in filt_set:\n",
    "            if filt in filter_features.keys():\n",
    "                filter_features[filt] += 1\n",
    "            else:\n",
    "                filter_features[filt] = 1\n",
    "    \n",
    "    # Format Output for Table\n",
    "    print qtype.upper()\n",
    "    print ' '\n",
    "    print 'Make filter table {} rows (plus 1 for heading)'.format(len(filter_features))\n",
    "    print ' '\n",
    "    sorted_filts = sorted(filter_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_filts:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '\n",
    "    print 'Make query table {} rows (plus 1 for heading)'.format(len(query_features))\n",
    "    print ' '\n",
    "    sorted_queries = sorted(query_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_queries:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Specially Selected Question Distribution (in case of special eval on DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT FACT\n",
      " \n",
      "Make filter table 14 rows (plus 1 for heading)\n",
      " \n",
      "phone 13\n",
      "name 6\n",
      "title 5\n",
      "content 5\n",
      "location 5\n",
      "post_date 3\n",
      "age 3\n",
      "height 3\n",
      "email 3\n",
      "review_site_id 2\n",
      "hair_color 2\n",
      "weight 1\n",
      "price 1\n",
      "ethnicity 1\n",
      " \n",
      "Make query table 11 rows (plus 1 for heading)\n",
      " \n",
      "name 2\n",
      "review_site_id 2\n",
      "email 2\n",
      "age 2\n",
      "weight 1\n",
      "price 1\n",
      "hair_color 1\n",
      "height 1\n",
      "services 1\n",
      "social_media_id 1\n",
      "ethnicity 1\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for qtype in question_type.keys():\n",
    "    filter_features = {}\n",
    "    query_features = {}\n",
    "    agg_function = {}\n",
    "    # Obtain questions\n",
    "    file_path = question_type[qtype]\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "    # Find features of question\n",
    "    for question in data:\n",
    "        if question['id'] in selected_questions[qtype]:\n",
    "            qlines = question['SPARQL'][-1].split('\\n')\n",
    "            # Find what feature is queried\n",
    "            if qtype not in ['Cluster Identification', 'Cluster Facet']:\n",
    "                qfeat = extract_query(qtype, qlines)\n",
    "                if qfeat in query_features.keys():\n",
    "                    query_features[qfeat] += 1\n",
    "                else:\n",
    "                    query_features[qfeat] = 1\n",
    "            filt_set = extract_filter(qtype, qlines)\n",
    "            for filt in filt_set:\n",
    "                if filt in filter_features.keys():\n",
    "                    filter_features[filt] += 1\n",
    "                else:\n",
    "                    filter_features[filt] = 1\n",
    "    \n",
    "    # Format Output for Table\n",
    "    print qtype.upper()\n",
    "    print ' '\n",
    "    print 'Make filter table {} rows (plus 1 for heading)'.format(len(filter_features))\n",
    "    print ' '\n",
    "    sorted_filts = sorted(filter_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_filts:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '\n",
    "    print 'Make query table {} rows (plus 1 for heading)'.format(len(query_features))\n",
    "    print ' '\n",
    "    sorted_queries = sorted(query_features.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for tup in sorted_queries:\n",
    "        print tup[0], tup[1]\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "print data[0]['SPARQL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'height' in qlines[1]:\n",
    "    print \"hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qlines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question_Distribution.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check_Chosen_Seeds.ipynb\r\n",
      "Domain_Discovery_Clustering_and_Question_Selection.ipynb\r\n",
      "Now_Get_ISI_Late_Submission.ipynb\r\n",
      "OLD_Check_Chosen_Seeds2.ipynb\r\n",
      "chosen_questions.json\r\n",
      "cluster_annotation_data.json\r\n",
      "seeds.xlsx\r\n",
      "seeds_debug.xlsx\r\n"
     ]
    }
   ],
   "source": [
    "ls ../data/annotation_prep/dd_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster Identification': ['17', '49', '19', '37', '29', '50', '3']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
