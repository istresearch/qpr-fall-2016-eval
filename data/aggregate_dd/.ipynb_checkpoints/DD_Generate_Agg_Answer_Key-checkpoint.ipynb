{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(extractions, feature):\n",
    "    norm_extractions = []\n",
    "    for entry in extractions:\n",
    "        entry = float(entry)\n",
    "        if feature == 'weight':\n",
    "            if entry < 80:\n",
    "                entry = entry * 2.20462\n",
    "        elif feature == 'height':\n",
    "            if entry > 100:\n",
    "                entry = entry * 0.393701\n",
    "        norm_extractions.append(entry)\n",
    "        \n",
    "    return norm_extractions \n",
    "\n",
    "def aggregate(norm_extractions, function):\n",
    "    if function == 'MIN':\n",
    "        agg_answer = numpy.min(norm_extractions)\n",
    "    elif function == 'MAX':\n",
    "        agg_answer = numpy.max(norm_extractions)\n",
    "    elif function == 'AVG':\n",
    "        agg_answer = numpy.mean(norm_extractions)\n",
    "    elif function == 'MODE':\n",
    "        agg_answer = max(set(norm_extractions), key=norm_extractions.count)\n",
    "        \n",
    "    return agg_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd_answers_file = '../post_hoc_annotations/post_hoc_cluster_aggregate-cleaned.json'\n",
    "\n",
    "with open(dd_answers_file, 'r') as f:\n",
    "    dd_answers = eval(f.read())\n",
    "    \n",
    "agg_quest_file = '../../questions/post_aggregate_V2.json'\n",
    "\n",
    "# Get the type\n",
    "with open(agg_quest_file, 'r') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        if entry['id'] in dd_answers.keys():\n",
    "            dd_answers[entry['id']]['type'] = entry['type']\n",
    "            feature = (entry['SPARQL'][0].split('\\n')[1]\n",
    "                       .split('?')[1].split(' ')[0].strip(')'))\n",
    "            dd_answers[entry['id']]['feature'] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 JPL\n",
      "69 JPL\n",
      "82 JPL\n",
      "83 JPL\n",
      "78 JPL\n",
      "79 JPL\n",
      "4 JPL\n",
      "68 JPL\n"
     ]
    }
   ],
   "source": [
    "answer_key = {}\n",
    "\n",
    "for qid in dd_answers.keys():\n",
    "    answer_key[qid] = {}\n",
    "    answer_key[qid]['question_text'] = dd_answers[qid]['question_text']\n",
    "    answer_key[qid]['type'] = dd_answers[qid]['type']\n",
    "    answer_key[qid]['feature'] = dd_answers[qid]['feature']\n",
    "    for dataset in ['NYU', 'JPL', 'HG']:\n",
    "        lower_dataset = dataset.lower()\n",
    "        answer_key[qid][dataset] = {}\n",
    "        answer_key[qid][dataset]['relevant_ads'] = []\n",
    "        answer_key[qid][dataset]['extractions'] = []\n",
    "        answer_key[qid][dataset]['norm_extractions'] = []\n",
    "        if lower_dataset in  dd_answers[qid]['relevant_ads'].keys():\n",
    "            answer_key[qid][dataset]['relevant_ads'] = dd_answers[qid]['relevant_ads'][lower_dataset].keys()\n",
    "            for ad in dd_answers[qid]['relevant_ads'][lower_dataset].keys():\n",
    "                answer_key[qid][dataset]['extractions'].extend(dd_answers[qid]['relevant_ads'][lower_dataset][ad])\n",
    "                norm_extractions = normalize(dd_answers[qid]['relevant_ads'][lower_dataset][ad], dd_answers[qid]['feature'])\n",
    "                answer_key[qid][dataset]['norm_extractions'].extend(norm_extractions)\n",
    "        final_norm_extractions = answer_key[qid][dataset]['norm_extractions']\n",
    "        if len(final_norm_extractions) > 0:\n",
    "            answer_key[qid][dataset]['agg_answer'] = aggregate(final_norm_extractions, dd_answers[qid]['type'])\n",
    "        else:\n",
    "            answer_key[qid][dataset]['agg_answer'] = 'No relevant extractions found'\n",
    "            print qid, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating no extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevant_ads': ['D3288181DEA19DD81C1E521AA182068BA48B737A08BD02B780B0D4D9D074E836'], 'extractions': [], 'norm_extractions': [], 'agg_answer': 'No relevant extractions found'}\n",
      "\n",
      "{'D3288181DEA19DD81C1E521AA182068BA48B737A08BD02B780B0D4D9D074E836': []}\n"
     ]
    }
   ],
   "source": [
    "qid = '71'\n",
    "\n",
    "print answer_key[qid]['JPL']\n",
    "print \n",
    "\n",
    "print dd_answers[qid]['relevant_ads']['jpl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_answer_key_file = 'dd_agg_answer_key_REWRITE.json'\n",
    "with open(agg_answer_key_file, 'w') as outfile:\n",
    "        json.dump(answer_key, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_list = [5, 4, 4, 1, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = max(set(my_list), key=my_list.count)\n",
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
