Note the notebook 'Chosen_Queries_V2.ipynb' was first used to choose relevant question submissions from each team, as 
they appeared.  Following this initial selection, the filtering feature values for each question was changed based on 
the number of expected relevant ads to be returned from the Ground Truth data set.  This process took place here: 
https://github.com/istresearch/memex-search-evaluation/tree/master/automated_aggregate_sparql/notebook/offline_versions/pure_aggregates

Following this second selection process, limited annotation files were used to determine:
1) If the selected feature values chosen for the Ground Truth data set might return relevant documents from the NYU data set
2) If not, what new selected feature values might return relevant documents from the NYU data set.
This process took place in this repo

